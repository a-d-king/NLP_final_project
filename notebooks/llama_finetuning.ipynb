{"cells":[{"cell_type":"markdown","metadata":{"id":"IqM-T1RTzY6C"},"source":["# Llama 3.1 8B Fine-Tuning\n","## Note\n","\n","This notebook was adapted from Unsloth's published notebook on fine-tuning Llama 3.1 8B. The original notebook can be found here: https://colab.research.google.com/drive/135ced7oHytdxu3N2DNe1Z0kqjyYIkDXp?usp=sharing#scrollTo=QmUBVEnvCDJv"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2eSvM9zX_2d3"},"outputs":[],"source":["%%capture\n","# Installs Unsloth, Xformers (Flash Attention) and all other packages!\n","!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n","!pip install --no-deps \"xformers<0.0.27\" \"trl<0.9.0\" peft accelerate bitsandbytes"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24213,"status":"ok","timestamp":1723427545137,"user":{"displayName":"Tarun Vallabhaneni","userId":"14041432992530701793"},"user_tz":300},"id":"72JFvGUM1LR6","outputId":"839aa617-72db-46ff-8c59-d177b20e1ad0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5686,"status":"ok","timestamp":1723317900654,"user":{"displayName":"Tarun Vallabhaneni","userId":"14041432992530701793"},"user_tz":300},"id":"3vW_22ohHjCf","outputId":"9bb01dbc-e7fb-45e2-f851-947b4091b31b"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/7.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m6.9/7.1 MB\u001b[0m \u001b[31m207.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m196.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m97.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install wandb -qU"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a5gtY5x8HmMi"},"outputs":[],"source":["# Log in to your W&B account\n","import wandb\n","\n","# Use wandb-core, temporary for wandb's new backend\n","wandb.require(\"core\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":106},"executionInfo":{"elapsed":5821,"status":"ok","timestamp":1723317906893,"user":{"displayName":"Tarun Vallabhaneni","userId":"14041432992530701793"},"user_tz":300},"id":"4JreiwdqLTUW","outputId":"c44d1971-0e13-4b15-96b0-e74a3ceb7903"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n"]},{"data":{"application/javascript":"\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ","text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/plain":["True"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["wandb.login()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":162},"executionInfo":{"elapsed":1904,"status":"ok","timestamp":1723317908794,"user":{"displayName":"Tarun Vallabhaneni","userId":"14041432992530701793"},"user_tz":300},"id":"bPAPG4stIBU0","outputId":"c09e7895-3752-42af-8fc2-d77995ecb9a0"},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtvallabh\u001b[0m (\u001b[33mtvallabh-university-of-chicago\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["Tracking run with wandb version 0.17.6"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/content/wandb/run-20240810_192506-2ufzn07m</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/tvallabh-university-of-chicago/TextExpansions_NLP/runs/2ufzn07m' target=\"_blank\">LLAMA 8B run_5</a></strong> to <a href='https://wandb.ai/tvallabh-university-of-chicago/TextExpansions_NLP' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/tvallabh-university-of-chicago/TextExpansions_NLP' target=\"_blank\">https://wandb.ai/tvallabh-university-of-chicago/TextExpansions_NLP</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/tvallabh-university-of-chicago/TextExpansions_NLP/runs/2ufzn07m' target=\"_blank\">https://wandb.ai/tvallabh-university-of-chicago/TextExpansions_NLP/runs/2ufzn07m</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/tvallabh-university-of-chicago/TextExpansions_NLP/runs/2ufzn07m?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x79ec16aaf7f0>"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["wandb.init(project=\"TextExpansions_NLP\", name=\"LLAMA 8B run_5\")"]},{"cell_type":"markdown","metadata":{"id":"WHUS_fnhTJzb"},"source":["# Data Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"awUzOgNf1T1T"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import torch\n","csv_expansions = '/content/drive/My Drive/NLP Final Project Data/df_combined_expansions.csv'\n","df_expansions = pd.read_csv(csv_expansions)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":597},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1723317913152,"user":{"displayName":"Tarun Vallabhaneni","userId":"14041432992530701793"},"user_tz":300},"id":"GfCmmxpK1wXV","outputId":"557b549c-2311-44c3-a7e8-f63623d4ab4a"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"summary":"{\n  \"name\": \"df_expansions\",\n  \"rows\": 1500,\n  \"fields\": [\n    {\n      \"column\": \"notes\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1500,\n        \"samples\": [\n          \"The structure of a trie allows it to perform operations like prefix searching and retrieval of all keys with a given prefix efficiently compared to other data structures.\",\n          \"DFS can also be utilized for topological sorting of directed acyclic graphs, allowing for a linear ordering of vertices that respects their dependencies.\",\n          \"Integration testing focuses on verifying the interactions between different modules or services within an application to detect interface defects.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"expanded_content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1500,\n        \"samples\": [\n          \"# The Structure of a Trie and Its Efficiency in Operations\\n\\nA trie, also known as a prefix tree, is a specialized tree-like data structure that is particularly useful for storing a dynamic set of strings. It is designed in a way that allows for efficient retrieval of keys based on their prefixes, making it an ideal choice for applications such as autocomplete systems, spell checkers, and IP routing. Unlike traditional data structures like hash tables or binary search trees, tries organize data based on the structure of the stored keys, where common prefixes are shared among keys, thus reducing redundancy and improving retrieval speed.\\n\\n## Structure and Basic Properties\\n\\nA trie consists of nodes, where each node represents a character of a string. The root node is typically empty, and each path from the root to a leaf node corresponds to a unique string in the trie. Each node has the following critical properties:\\n\\n1. **Children**: A node can have multiple children representing the possible next characters in the keys.\\n2. **End of Word Marker**: Each node can have a boolean flag indicating whether it marks the end of a valid string. This allows the trie to differentiate between a key that is a prefix of another key and a complete key itself.\\n3. **Path Representation**: The path from the root to any given node represents the characters of strings that share the prefix up to that node.\\n\\n### Basic Operations\\n\\nTries support a variety of operations that leverage their unique structure, the most notable being insertion, searching, and deletion.\\n\\n#### Insertion\\n\\nTo insert a new key into a trie, we start at the root node and traverse down following the characters of the string. For each character, if the corresponding child node does not exist, a new node is created. Once all characters of the string are processed, the final node is marked as an end-of-word node. This operation takes O(m) time, where m is the length of the string being inserted.\\n\\n#### Searching\\n\\nThe search operation is straightforward. It follows the same path as insertion by traversing the trie according to the characters of the input string. If we reach a node corresponding to the final character of the string and that node is marked as an end node, the string is found. This also runs in O(m) time, making tries particularly efficient for prefix searches compared to other data structures.\\n\\n#### Prefix Searching\\n\\nA key advantage of tries is their ability to efficiently retrieve all keys with a given prefix. To find all strings sharing a specific prefix, one first navigates to the corresponding node representing the end of the prefix. From there, a depth-first search (DFS) can be performed to explore all descendant nodes, collecting complete string representations by concatenating characters along the path to each terminal node. This operation can be performed in O(m + k) time, where k is the number of strings found with the given prefix, significantly optimizing the retrieval process in scenarios where many keys share a common prefix.\\n\\n### Comparison with Other Data Structures\\n\\nTries outperform various other data structures in specific scenarios, notably in prefix-related queries. For instance, if using a hash table, the time complexity to find all keys with a prefix could be O(n), where n is the number of keys, since one would likely need to scan through all entries to filter them. In contrast, tries' structured approach means that they can access the relevant nodes directly, providing more efficient and organized prefix queries.\\n\\nAdditionally, tries can save space when many keys share common prefixes. While the worst-case space complexity is O(n * m), trends in real-world data often allow for higher space efficiency due to the prefix-sharing nature. This characteristic can be particularly crucial in applications like search engines or text autocomplete features, where performance and storage efficiency are vital.\\n\\n### Conclusion\\n\\nThe structure of a trie not only enables efficient prefix searching but also optimizes the retrieval of all keys associated with a specific prefix. This makes it a valuable tool in applications requiring fast and organized string storage and access, highlighting its advantages over traditional data structures.\",\n          \"# Depth-First Search (DFS) and Topological Sorting in Directed Acyclic Graphs (DAGs)\\n\\nDepth-First Search (DFS) is a fundamental algorithm in computer science used to traverse or search through graph structures. One significant application of DFS is topological sorting, particularly in directed acyclic graphs (DAGs). This process involves arranging the vertices of a graph in a linear sequence such that, for every directed edge from vertex u to vertex v, u appears before v in the ordering. Understanding how DFS facilitates topological sorting reveals the interplay between graph theory and algorithm design, making it a crucial concept for students pursuing computer science.\\n\\n### Directed Acyclic Graphs (DAGs)\\n\\nBefore diving into topological sorting, it is essential to grasp what a DAG is. A directed acyclic graph is a directed graph that contains no cycles; that is, there is no way to start at a vertex and return to it following the directed edges. This property makes DAGs ideal for representing structures with dependencies, such as task scheduling, project management, and prerequisite relationships in courses. Recognizing the significance of acyclic properties allows students to relate graph theory to real-world applications effectively.\\n\\n### Topological Sort Concept\\n\\nTopological sorting yields a linear order of vertices that adheres to dependency relationships dictated by the directed edges. For instance, when a graph represents tasks where one task must precede another, the topological order signifies a valid sequence of task completion. Importantly, topological sorting is only applicable to directed acyclic graphs; if cycles exist, no such ordering will suffice. Given a graph G with vertices V and edges E, we denote a topological sort as a permutation of V that meets the required conditions outlined.\\n\\n### Utilizing DFS for Topological Sorting\\n\\nDFS serves as an efficient method for achieving topological sorting. The core procedure begins by marking all vertices as unvisited, and as the algorithm explores each vertex deeply through recursive calls, it pushes each vertex onto a stack once all its adjacent vertices are processed. This ensures that when a vertex is added to the stack, all its descendants are already accounted for, fulfilling the topological sort requirement.\\n\\nThe steps are as follows:\\n\\n1. **Initialization**: Start with an empty stack and mark all vertices as unvisited.\\n2. **DFS Traversal**: For each unvisited vertex, perform a DFS. \\n   - Mark the vertex as visited.\\n   - Recur for all its unvisited adjacent vertices.\\n   - Once the vertex has no adjacent vertices left to visit, push it onto the stack.\\n3. **Stack Extraction**: Once all vertices have been processed, the stack will contain the topologically sorted order. When popped, the stack results in a linear ordering respecting the directed edges.\\n\\nThis algorithm is efficient, typically running in O(V + E) time, where V is the number of vertices and E is the number of edges. The efficiency stems from the fact that each vertex and edge is explored a single time.\\n\\n### Applications of Topological Sorting\\n\\nThe applications of topological sorting extend to various fields. In project scheduling, for example, determining the order of tasks based on dependencies helps in effective planning. In computer science, compilers can utilize topological sorting to resolve symbol dependencies when compiling code. By ensuring that each dependency is addressed before its use, compilers can build efficient execution plans that reduce runtime errors.\\n\\nMoreover, database systems may leverage topological sorting for query optimization, where the execution order of SQL queries must respect their dependencies.\\n\\nIn concluding this discussion on DFS and topological sorting, it is apparent that these concepts are interwoven with practical applications in algorithm design and computational problem-solving. By understanding how DFS facilitates topological sorting in DAGs, students gain insight into both the theory and applicability of graph algorithms in real-world scenarios.\",\n          \"# Integration Testing\\n\\nIntegration testing is a crucial phase in the software development lifecycle, focused on evaluating the interactions between different modules or services within an application. After individual components have been tested through unit testing, integration testing aims to ensure that these components work together as intended. This stage helps to uncover defects that might arise from the interaction of components, which are not visible during isolated testing. By identifying and addressing issues early in the integration phase, developers can significantly enhance system reliability and performance.\\n\\nOne of the primary goals of integration testing is to validate interfaces and the flow of data between modules. It is essential because independent testing of modules does not account for how these components will coexist in a larger system architecture. Typical problems observed during integration testing include discrepancies in data formats, unexpected interactions, and performance bottlenecks that only manifest when modules communicate. Therefore, a robust integration testing strategy helps in ensuring seamless cooperation between components, ultimately leading to a more stable application.\\n\\nIntegration testing can be categorized into various approaches based on the structure and requirements of the application. The most common strategies include:\\n\\n1. **Big Bang Integration Testing**: In this approach, all modules are integrated simultaneously; after which the entire system is tested as a whole. While this method simplifies the testing process, it may lead to challenges in identifying where the faults lie within the system. \\n\\n2. **Top-Down Integration Testing**: This technique involves starting integration testing from the top-level modules and progressively integrating lower-level modules. Here, stubs (dummy programs) are often used in place of the lower-level modules during the initial testing phases. Top-down testing provides early feedback on how high-level functionalities are working.\\n\\n3. **Bottom-Up Integration Testing**: Contrary to the top-down approach, bottom-up testing begins with the lowest-level modules and gradually integrates them into higher-level modules. Drivers (temporary programs) are used to simulate the behavior of upper modules when they are not ready yet. This method enables thorough testing of foundational components before integrating them into the whole system.\\n\\n4. **Sandwich Integration Testing**: This is a hybrid approach combining both top-down and bottom-up methods. This strategy allows for parallel development and testing of various modules while ensuring that system features are continuously evaluated throughout the integration process.\\n\\nIn terms of tool support, numerous software tools have been developed to facilitate integration testing. Common tools include Selenium for web applications, Postman for API testing, and JUnit for Java applications. These tools help in automating the testing process, managing test cases, and tracking defects efficiently. Automation in integration testing is particularly essential to handle complex systems with many interdependencies, allowing developers to run tests regularly and get immediate feedback.\\n\\nTo successfully implement integration testing, it is vital to establish clear integration points and interfaces between modules at the design stage. A well-defined interface will contribute significantly to the ease of future integration testing, as it dictates how data should flow between modules. Furthermore, employing continuous integration/continuous deployment (CI/CD) practices can enhance integration testing by automating builds and tests every time new code is committed, ensuring stability and quality in codebases.\\n\\nOverall, integration testing is an indispensable activity in software development that assesses the cooperation of diverse system components. By addressing potential integration issues early, teams can ensure that the final product is robust and functions as intended, paving the way for a smooth transition into system testing and deployment.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}","type":"dataframe","variable_name":"df_expansions"},"text/html":["\n","  <div id=\"df-b4150f38-67d2-4ce4-a424-d7cb13a8d287\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>notes</th>\n","      <th>expanded_content</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Algorithms are step-by-step procedures or form...</td>\n","      <td># Algorithms: The Foundation of Computer Progr...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Data structures are methods for organizing and...</td>\n","      <td># Data Structures: Organizing and Storing Data...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Sorting algorithms, such as quicksort and merg...</td>\n","      <td># Sorting Algorithms: An Overview\\n\\nSorting a...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Searching algorithms enable the identification...</td>\n","      <td># Searching Algorithms: Linear and Binary Sear...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Big O notation is a mathematical representatio...</td>\n","      <td># Big O Notation\\n\\nBig O notation is a mathem...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1495</th>\n","      <td>Suffix trees can be constructed for multiple s...</td>\n","      <td># Suffix Trees for Multiple Strings\\n\\nSuffix ...</td>\n","    </tr>\n","    <tr>\n","      <th>1496</th>\n","      <td>One key operation on suffix trees is the const...</td>\n","      <td># Suffix Trees and Suffix Links\\n\\nSuffix tree...</td>\n","    </tr>\n","    <tr>\n","      <th>1497</th>\n","      <td>Suffix trees play a crucial role in the field ...</td>\n","      <td># Suffix Trees and Their Role in Data Compress...</td>\n","    </tr>\n","    <tr>\n","      <th>1498</th>\n","      <td>Visualization of suffix trees helps in underst...</td>\n","      <td># Visualization of Suffix Trees: Understanding...</td>\n","    </tr>\n","    <tr>\n","      <th>1499</th>\n","      <td>Despite their advantages, suffix trees can be ...</td>\n","      <td># Suffix Trees vs. Suffix Arrays: Memory Overh...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1500 rows × 2 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b4150f38-67d2-4ce4-a424-d7cb13a8d287')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-b4150f38-67d2-4ce4-a424-d7cb13a8d287 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-b4150f38-67d2-4ce4-a424-d7cb13a8d287');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-6f935c58-3c1b-4a1b-9927-02736cec0fb5\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6f935c58-3c1b-4a1b-9927-02736cec0fb5')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-6f935c58-3c1b-4a1b-9927-02736cec0fb5 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_4006c84c-223a-4f35-85b3-623ec1c7ef84\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_expansions')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_4006c84c-223a-4f35-85b3-623ec1c7ef84 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df_expansions');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"text/plain":["                                                  notes  \\\n","0     Algorithms are step-by-step procedures or form...   \n","1     Data structures are methods for organizing and...   \n","2     Sorting algorithms, such as quicksort and merg...   \n","3     Searching algorithms enable the identification...   \n","4     Big O notation is a mathematical representatio...   \n","...                                                 ...   \n","1495  Suffix trees can be constructed for multiple s...   \n","1496  One key operation on suffix trees is the const...   \n","1497  Suffix trees play a crucial role in the field ...   \n","1498  Visualization of suffix trees helps in underst...   \n","1499  Despite their advantages, suffix trees can be ...   \n","\n","                                       expanded_content  \n","0     # Algorithms: The Foundation of Computer Progr...  \n","1     # Data Structures: Organizing and Storing Data...  \n","2     # Sorting Algorithms: An Overview\\n\\nSorting a...  \n","3     # Searching Algorithms: Linear and Binary Sear...  \n","4     # Big O Notation\\n\\nBig O notation is a mathem...  \n","...                                                 ...  \n","1495  # Suffix Trees for Multiple Strings\\n\\nSuffix ...  \n","1496  # Suffix Trees and Suffix Links\\n\\nSuffix tree...  \n","1497  # Suffix Trees and Their Role in Data Compress...  \n","1498  # Visualization of Suffix Trees: Understanding...  \n","1499  # Suffix Trees vs. Suffix Arrays: Memory Overh...  \n","\n","[1500 rows x 2 columns]"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["df_expansions"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":299,"referenced_widgets":["a6ae176d88d54fc5b06382b93f953340","66aeebe7538e4034bc79b4919d9d2dcd","2d9b683a514f44b8aeeeb91bf09335b8","4f709ea116504c06b935164f17033a2a","d2cfa05227274df5bbaa1906011482c5","e8ded83de37740e5b01ac578ec0caf89","1f0cff853cfa4337aa78fbaeaac3b781","936b5e41270a411fbad754297ea85480","807353ff8c0c40c09b552c65b1a014d0","f0884ec8d6ea494eaaf3b1fdb10c1a58","2b173a01f971458782f913b0fc518203","8e416d25d24a43fda6e32772c8f1254b","726c371a807341bba4c166bb3d7e4cf2","6116a8d8133d43f691f13babafaf21b1","a0139421746a47fe9100dd2d51f008e8","9d87b6dbd5e040da9fee8938800c8564","73950018b9874d17bf94bc31ffa3c6e8","0ce50666c0074d43854298c0eb4aad34","ff23c97dd8c04cfe872e8e8d8fe3d378","4283c8e6204246f1bdd2479fa14858b8","9ace2359a8824913877180b4743ad104","c41949581145451d89d178ba853a3d7c","b0fa405d4e5740b0b76da36e6d09fbb1","8774933244864d98a94c67d54040f7d4","4a82a1f7f0c74b209fff515103254e92","b1f30e1bf9984b3eaaf4b55e97e32355","c1d20772376b454482994e36e14193c3","d0cdad457a024eb3bdc50823bc99ad3c","5f867cb94def411381615d2448facbbe","9be948479d4b4984a66d799fc38ef931","6c3bc83eedc3426eab31cc4eff3acb2d","ddca7425fe2548aa8b69991123932c90","5d542214fa5b4e57b4a173e6821635d0","1882a35635fc40a09cc64dd8980c52ef","bfd11c7cdfb14e08a8eaf14df7d0c2e1","71071d14ea894a23bfdc91cfe9cb82fd","5a4e62ee241a4dd4b2b3fabb13542caa","ee8f1835a95043989f77adc8d876063f","5f74db3a779548a59abae59cfa5e414f","449b8e23151c4a228f27b5eb6531e295","3b42b0dbd3854c4baa57394475beee45","45932f6a791f4d00806844d9f1ab7d78","25755d03fbdc42c1b91af5861b5e8ff2","27553a8863834b0197be5db14092fc77","1326089ddb8f4be4954a11c772f3a68a","068b2dd671314903ae5f3b7ada76f4f7","b408f64cbabc4173ba59517f61016386","f238fbb4b5294fedbb70492bd96fa2ac","e4d03ae801744b10b1d51a0d51ff6295","7f97762caade48e7ac47455ac4dee749","ad19a1332abd4a6c8b09d85b2cd89540","52533fc9671c4ea5996dbaeb94bae905","43199e19ac254902aa09ee42b0622cec","a4ab84665b2e400c9b8ea400d3fd3517","eb4db9b805594e11829474747dea80ed"]},"executionInfo":{"elapsed":45372,"status":"ok","timestamp":1723427619532,"user":{"displayName":"Tarun Vallabhaneni","userId":"14041432992530701793"},"user_tz":300},"id":"3Rdf-cxgToio","outputId":"8176a0be-1c3b-42d9-efb8-796531b7d85a"},"outputs":[{"name":"stdout","output_type":"stream","text":["🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","==((====))==  Unsloth 2024.8: Fast Llama patching. Transformers = 4.44.0.\n","   \\\\   /|    GPU: NVIDIA A100-SXM4-40GB. Max memory: 39.564 GB. Platform = Linux.\n","O^O/ \\_/ \\    Pytorch: 2.3.1+cu121. CUDA = 8.0. CUDA Toolkit = 12.1.\n","\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = False]\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a6ae176d88d54fc5b06382b93f953340","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/5.70G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8e416d25d24a43fda6e32772c8f1254b","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/230 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b0fa405d4e5740b0b76da36e6d09fbb1","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1882a35635fc40a09cc64dd8980c52ef","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1326089ddb8f4be4954a11c772f3a68a","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/345 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from unsloth import FastLanguageModel\n","import torch\n","max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n","dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n","load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n","\n","# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n","fourbit_models = [\n","    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 15 trillion tokens model 2x faster!\n","    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n","    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n","    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # We also uploaded 4bit for 405b!\n","    \"unsloth/Mistral-Nemo-Base-2407-bnb-4bit\", # New Mistral 12b 2x faster!\n","    \"unsloth/Mistral-Nemo-Instruct-2407-bnb-4bit\",\n","    \"unsloth/mistral-7b-v0.3-bnb-4bit\",        # Mistral v3 2x faster!\n","    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n","    \"unsloth/Phi-3-mini-4k-instruct\",          # Phi-3 2x faster!d\n","    \"unsloth/Phi-3-medium-4k-instruct\",\n","    \"unsloth/gemma-2-9b-bnb-4bit\",\n","    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n","] # More models at https://huggingface.co/unsloth\n","\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",\n","    max_seq_length = max_seq_length,\n","    dtype = dtype,\n","    load_in_4bit = load_in_4bit,\n","    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4073,"status":"ok","timestamp":1723421354956,"user":{"displayName":"Tarun Vallabhaneni","userId":"14041432992530701793"},"user_tz":300},"id":"_JypdBWB16HU","outputId":"e5727ab2-201a-4d8f-dc6b-8be2e8036420"},"outputs":[{"name":"stdout","output_type":"stream","text":["Notes Token Counts: 0       27\n","1       31\n","2       33\n","3       27\n","4       29\n","        ..\n","1495    23\n","1496    26\n","1497    28\n","1498    22\n","1499    27\n","Name: notes, Length: 1500, dtype: int64\n","Expansions Token Counts: 0       733\n","1       839\n","2       860\n","3       755\n","4       822\n","       ... \n","1495    751\n","1496    743\n","1497    764\n","1498    687\n","1499    724\n","Name: expanded_content, Length: 1500, dtype: int64\n"]}],"source":["def count_tokens(text, tokenizer):\n","    \"\"\"\n","    Count the number of tokens in a text using the provided tokenizer.\n","    Parameters:\n","        text (str): The text to count tokens in.\n","        tokenizer (transformers.PreTrainedTokenizerFast): The tokenizer to use.\n","    \"\"\"\n","    tokens = tokenizer(text, return_tensors=\"pt\")[\"input_ids\"].shape[1]\n","    return tokens\n","\n","# Count tokens in 'notes' and 'expanded_content' columns\n","notes_token_counts = df_expansions['notes'].apply(lambda x: count_tokens(x, tokenizer))\n","expansions_token_counts = df_expansions['expanded_content'].apply(lambda x: count_tokens(x, tokenizer))\n","\n","# Print the token counts\n","print(\"Notes Token Counts:\", notes_token_counts)\n","print(\"Expansions Token Counts:\", expansions_token_counts)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cx9vGJIb30v4"},"outputs":[],"source":["# Count tokens in 'notes' and 'expanded_content' columns\n","df_expansions['notes_token_count'] = df_expansions['notes'].apply(lambda x: count_tokens(x, tokenizer))\n","df_expansions['expansions_token_count'] = df_expansions['expanded_content'].apply(lambda x: count_tokens(x, tokenizer))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1723421360814,"user":{"displayName":"Tarun Vallabhaneni","userId":"14041432992530701793"},"user_tz":300},"id":"yRTUx7J34qAi","outputId":"f43d1493-6998-4bbd-fd53-dadbb80bd30c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Statistics for 'notes_token_count':\n","count    1500.000000\n","mean       29.266667\n","std         4.025049\n","min        19.000000\n","25%        26.000000\n","50%        29.000000\n","75%        32.000000\n","max        52.000000\n","Name: notes_token_count, dtype: float64\n","\n","Statistics for 'expansions_token_count':\n","count    1500.000000\n","mean      759.546667\n","std        52.927567\n","min       600.000000\n","25%       723.000000\n","50%       757.000000\n","75%       793.000000\n","max      1006.000000\n","Name: expansions_token_count, dtype: float64\n"]}],"source":["# Descriptive statistics for 'notes_token_count'\n","notes_stats = df_expansions['notes_token_count'].describe()\n","print(\"Statistics for 'notes_token_count':\")\n","print(notes_stats)\n","\n","# Descriptive statistics for 'expansions_token_count'\n","expansions_stats = df_expansions['expansions_token_count'].describe()\n","print(\"\\nStatistics for 'expansions_token_count':\")\n","print(expansions_stats)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1723421361951,"user":{"displayName":"Tarun Vallabhaneni","userId":"14041432992530701793"},"user_tz":300},"id":"aR7XNSLB3-k7","outputId":"9099b9b9-3d42-4444-da80-deca965a18bf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Original dataframe shape: (1500, 4)\n","Filtered dataframe shape: (1499, 4)\n"]}],"source":["# Filter out rows where 'notes' or 'expanded_content' have more than 1000 tokens as they are cut off\n","filtered_df = df_expansions[(df_expansions['notes_token_count'] <= 1000) & (df_expansions['expansions_token_count'] <= 1000)]\n","\n","# Print the shape of the filtered dataframe to see how many rows were removed\n","print(f\"Original dataframe shape: {df_expansions.shape}\")\n","print(f\"Filtered dataframe shape: {filtered_df.shape}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WrDV-pVO5vuz"},"outputs":[],"source":["instructions = \"\"\"\n","    You are a computer science expert and a skilled writer.\n","\n","    Craft detailed content about the given computer science subtopic for university-level lecture notes, targeting a total of about 500 words distributed over a few paragraphs.\n","\n","    Begin with an introductory paragraph that lays the foundation of the subtopic. Follow this with detailed paragraphs focusing on the critical aspects of the subtopic. Include applications only if they are essential for understanding the concept; otherwise, concentrate on explaining the concept itself and its nuances.\n","\n","    You can selectively, if necessary, use examples, tables in Markdown format to illustrate key points, ensuring that any code provided is concise and directly demonstrates the concept, otherwise you don't need to include it.\n","\n","    Please also avoid overly detailed explanations of complex algorithms unless they are central to the subtopic. Do not go overboard with technical details that may overwhelm students.\n","\n","    Let's try to avoid generating code unless its short and obvious, otherwise, focus on detailed explanations and if you use equations, please use inline HTML. Quick and simple inline equations can utilize HTML ampersand entity codes, such as:\n","\n","        h<sub>&theta;</sub>(x) = &theta;<sub>o</sub> x + &theta;<sub>1</sub>x\n","\n","    This method works in practically all Markdown and does not require any external libraries. Avoid using LaTeX. If you cannot express it in HTML, please avoid using equations. Unless the symbol is simple and can be represented in HTML and Markdown, avoid using those symbols.\n","\n","    Let's try to avoid generating code unless its short and obvious, otherwise, focus on detailed explanations and if you use equations, please use LaTeX format.\n","\n","    Maintain clear and concise language suitable for a 10th-grade reading level, using academic language where appropriate. Avoid overly technical jargon unless it is necessary for clarity.\n","\n","    Also avoid your conclusion paragraph in the end since the content should be detailed throughout.\n","\n","    The entire response must be in valid Markdown format and avoid the use of diagrams unless they can be effectively represented in Markdown. You must stay in our limit of 500 words.\n","\n","    LaTeX is impossible to use in Markdown, so please use HTML for equations. Do not use LaTeX.\n","\n","    Your input will always be a single computer science subtopic, and your output should not conclude with a summarizing paragraph but rather emphasize detailed explanation throughout.\n","\n","\n","    Now, please generate detailed content about the subtopic in Markdown:\n","    \"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":398,"status":"ok","timestamp":1723421371829,"user":{"displayName":"Tarun Vallabhaneni","userId":"14041432992530701793"},"user_tz":300},"id":"ABwAnSNv5isS","outputId":"f00e07e1-e86e-4f3c-9eac-9081d433706c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Total tokens in 'notes': 43900\n","Total tokens in 'expanded_content': 1139320\n","Total tokens in 'instructions': 491\n"]}],"source":["# Get the total token count for 'notes' and 'expanded_content'\n","total_notes_tokens = df_expansions['notes_token_count'].sum()\n","total_expansions_tokens = df_expansions['expansions_token_count'].sum()\n","total_instr_tokens = count_tokens(instructions, tokenizer)\n","\n","# Print the total token counts\n","print(f\"Total tokens in 'notes': {total_notes_tokens}\")\n","print(f\"Total tokens in 'expanded_content': {total_expansions_tokens}\")\n","print(f\"Total tokens in 'instructions': {total_instr_tokens}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ihJ3zJ-tS-gm"},"outputs":[],"source":["from datasets import Dataset\n","\n","# training_df = pd.DataFrame()\n","# Create combined prompts with a new line after instructions\n","combined_prompts = filtered_df.apply(\n","    lambda row: f\"{instructions}\\nEXAMPLE:\\n\\n###INPUT (Notes): \\n {row['notes']}\\n\\n###OUTPUT (Expected Generations):\\n {row['expanded_content']}\", axis=1\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":353,"status":"ok","timestamp":1723421936836,"user":{"displayName":"Tarun Vallabhaneni","userId":"14041432992530701793"},"user_tz":300},"id":"ah_Ke6BjS_EV","outputId":"cc2a9c33-6446-4644-8c49-000e2dfd29dc"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","    You are a computer science expert and a skilled writer.\n","\n","    Craft detailed content about the given computer science subtopic for university-level lecture notes, targeting a total of about 500 words distributed over a few paragraphs.\n","\n","    Begin with an introductory paragraph that lays the foundation of the subtopic. Follow this with detailed paragraphs focusing on the critical aspects of the subtopic. Include applications only if they are essential for understanding the concept; otherwise, concentrate on explaining the concept itself and its nuances.\n","\n","    You can selectively, if necessary, use examples, tables in Markdown format to illustrate key points, ensuring that any code provided is concise and directly demonstrates the concept, otherwise you don't need to include it.\n","\n","    Please also avoid overly detailed explanations of complex algorithms unless they are central to the subtopic. Do not go overboard with technical details that may overwhelm students.\n","\n","    Let's try to avoid generating code unless its short and obvious, otherwise, focus on detailed explanations and if you use equations, please use inline HTML. Quick and simple inline equations can utilize HTML ampersand entity codes, such as:\n","\n","        h<sub>&theta;</sub>(x) = &theta;<sub>o</sub> x + &theta;<sub>1</sub>x\n","\n","    This method works in practically all Markdown and does not require any external libraries. Avoid using LaTeX. If you cannot express it in HTML, please avoid using equations. Unless the symbol is simple and can be represented in HTML and Markdown, avoid using those symbols.\n","\n","    Let's try to avoid generating code unless its short and obvious, otherwise, focus on detailed explanations and if you use equations, please use LaTeX format.\n","\n","    Maintain clear and concise language suitable for a 10th-grade reading level, using academic language where appropriate. Avoid overly technical jargon unless it is necessary for clarity.\n","\n","    Also avoid your conclusion paragraph in the end since the content should be detailed throughout.\n","\n","    The entire response must be in valid Markdown format and avoid the use of diagrams unless they can be effectively represented in Markdown. You must stay in our limit of 500 words.\n","\n","    LaTeX is impossible to use in Markdown, so please use HTML for equations. Do not use LaTeX.\n","\n","    Your input will always be a single computer science subtopic, and your output should not conclude with a summarizing paragraph but rather emphasize detailed explanation throughout.\n","\n","\n","    Now, please generate detailed content about the subtopic in Markdown:\n","    \n","EXAMPLE:\n","\n","###INPUT (Notes): \n"," Turing machines are theoretical devices that formalize the concept of computation, serving as a model for what it means to compute using algorithms.\n","\n","###OUTPUT (Expected Generations):\n"," # Turing Machines: The Foundation of Computation\n","\n","Turing machines, introduced by the mathematician Alan Turing in 1936, are abstract computational devices that play a crucial role in the field of computer science. They serve as a fundamental model for understanding the concept of computation and algorithms, providing insight into what it means to compute. A Turing machine consists of an infinite tape, a tape head that can read and write symbols on the tape, and a set of states that dictate how the machine behaves based on the current symbol it reads. This abstraction allows researchers and students to explore the limits of computation and the nature of algorithms in a precise way.\n","\n","## Components of a Turing Machine\n","\n","A Turing machine is comprised of several key components:\n","\n","1. **Tape**: The tape is infinite in both directions and is divided into discrete cells. Each cell can contain a symbol from a finite alphabet, including a special blank symbol which often denotes empty cells.\n","\n","2. **Tape Head**: This is the mechanism that reads the symbol in the current cell and can write a new symbol in that cell. The tape head can also move left or right, allowing it to access different cells of the tape.\n","\n","3. **State Register**: This stores the current state of the Turing machine. The machine can be in one of a finite number of states, which influence its operations.\n","\n","4. **Transition Function**: The transition function determines the behavior of the Turing machine based on the current state and the symbol being read. It specifies the new symbol to write, the direction to move the tape head (left or right), and the next state to transition to.\n","\n","Mathematically, the transition function can be expressed as:\n","\n","<b>&delta;: Q x &Sigma; -> Q x &Sigma; x {L, R}</b>\n","\n","Where **Q** is the set of states, **Σ** is the tape alphabet, **L** and **R** denote left and right movement, respectively.\n","\n","## Computation Process\n","\n","The operation of a Turing machine begins with the tape containing an input string and the tape head positioned at the start of that string. The machine reads the symbol under the tape head and utilizes the transition function to determine its next actions. For example, if it reads a symbol, the machine may write a different symbol in the same cell, move the head, and switch to another state. The process repeats until the machine reaches a designated halting state.\n","\n","This method of computation captures the essence of algorithmic problem-solving: a defined sequence of actions based on current conditions. Importantly, Turing machines can simulate any algorithm, which leads to the Church-Turing thesis, a foundational principle stating that any function that can be computed algorithmically can be computed by a Turing machine.\n","\n","## Variants and Extensions\n","\n","Numerous variants of Turing machines have been proposed to explore different aspects of computation. For example, a **nondeterministic Turing machine** is one where multiple transition options may be available, allowing for multiple potential outcomes from a single state. Although they are conceptually different, it has been proven that any computations performed by a nondeterministic Turing machine can also be performed by a deterministic one, meaning they have equivalent computational power.\n","\n","Additionally, an **oracle Turing machine** extends the concept further by including an \"oracle\" that can provide answers to specific problems instantaneously. This model is useful for studying complexity classes and understanding decision problems that may be infeasible for standard Turing machines.\n","\n","In practical applications, the concept of Turing machines has had widespread influence in computer science, particularly in understanding decidability and computational complexity. The limitations of what can be computed are illustrated beautifully through problems such as the Halting Problem, which proves that not all decision problems can be resolved algorithmically.\n","\n","Overall, Turing machines provide a fundamental framework for the theory of computation, shaping our understanding of algorithms and the limits of what can be achieved with computational systems. They remain a critical component of computer science education and theoretical exploration.\n","\n","    You are a computer science expert and a skilled writer.\n","\n","    Craft detailed content about the given computer science subtopic for university-level lecture notes, targeting a total of about 500 words distributed over a few paragraphs.\n","\n","    Begin with an introductory paragraph that lays the foundation of the subtopic. Follow this with detailed paragraphs focusing on the critical aspects of the subtopic. Include applications only if they are essential for understanding the concept; otherwise, concentrate on explaining the concept itself and its nuances.\n","\n","    You can selectively, if necessary, use examples, tables in Markdown format to illustrate key points, ensuring that any code provided is concise and directly demonstrates the concept, otherwise you don't need to include it.\n","\n","    Please also avoid overly detailed explanations of complex algorithms unless they are central to the subtopic. Do not go overboard with technical details that may overwhelm students.\n","\n","    Let's try to avoid generating code unless its short and obvious, otherwise, focus on detailed explanations and if you use equations, please use inline HTML. Quick and simple inline equations can utilize HTML ampersand entity codes, such as:\n","\n","        h<sub>&theta;</sub>(x) = &theta;<sub>o</sub> x + &theta;<sub>1</sub>x\n","\n","    This method works in practically all Markdown and does not require any external libraries. Avoid using LaTeX. If you cannot express it in HTML, please avoid using equations. Unless the symbol is simple and can be represented in HTML and Markdown, avoid using those symbols.\n","\n","    Let's try to avoid generating code unless its short and obvious, otherwise, focus on detailed explanations and if you use equations, please use LaTeX format.\n","\n","    Maintain clear and concise language suitable for a 10th-grade reading level, using academic language where appropriate. Avoid overly technical jargon unless it is necessary for clarity.\n","\n","    Also avoid your conclusion paragraph in the end since the content should be detailed throughout.\n","\n","    The entire response must be in valid Markdown format and avoid the use of diagrams unless they can be effectively represented in Markdown. You must stay in our limit of 500 words.\n","\n","    LaTeX is impossible to use in Markdown, so please use HTML for equations. Do not use LaTeX.\n","\n","    Your input will always be a single computer science subtopic, and your output should not conclude with a summarizing paragraph but rather emphasize detailed explanation throughout.\n","\n","\n","    Now, please generate detailed content about the subtopic in Markdown:\n","    \n","EXAMPLE:\n","\n","###INPUT (Notes): \n"," As edge computing grows, new standards and frameworks are emerging to facilitate communication and management of edge resources across diverse environments.\n","\n","###OUTPUT (Expected Generations):\n"," # Edge Computing Standards and Frameworks\n","\n","Edge computing represents a paradigm shift in how data is processed, managed, and delivered. By bringing computation and data storage closer to the data source, edge computing minimizes latency, reduces bandwidth usage, and enhances the overall efficiency of applications. As this technology rapidly evolves, new standards and frameworks are emerging to facilitate the communication and management of edge resources across varied environments. These developments are crucial in creating interoperability between devices and ensuring that edge computing systems operate seamlessly across different platforms.\n","\n","One of the critical aspects of edge computing is the establishment of communication protocols that enable devices and applications at the edge to communicate efficiently. Various organizations, such as the Edge Computing Consortium and the Industrial Internet Consortium, are actively working on defining these standards. For instance, MQTT (Message Queuing Telemetry Transport) and CoAP (Constrained Application Protocol) are examples of protocols designed for lightweight communication in devices with limited resources. MQTT is particularly effective for scenarios involving unreliable networks, as it uses a publish/subscribe model that significantly reduces bandwidth consumption.\n","\n","Another important dimension is edge orchestration, which involves the management of distributed resources at the edge. This includes tasks such as deploying applications, managing workloads, and ensuring resource availability. Frameworks like Kubernetes have been extended to support edge environments, providing developers with tools to automate the deployment of applications across various nodes. K3s (a lightweight version of Kubernetes) is specifically tailored for edge computing, enabling efficient management with minimal resource overhead. This orchestration layer is vital for maintaining the reliability and responsiveness of edge applications, especially in dynamic environments where resources may frequently change.\n","\n","Security also emerges as a major concern with the rise of edge computing. Given that edge devices can often be distributed over large geographical areas and may lack the robust security protections found in centralized systems, developing standards for secure communication and data transmission is imperative. Frameworks such as the Edge Computing Security Framework aim to establish guidelines for ensuring that data remains secure as it moves between edge devices and central data centers. This includes encryption methods, authentication protocols, and regular security updates to protect against vulnerabilities.\n","\n","Interoperability is another significant challenge in edge computing. As different manufacturers develop their edge devices and solutions, ensuring that these systems can work together is essential. This has led to the creation of standards such as OpenFog and the OASIS standard for interoperability in cloud and edge applications. These initiatives promote a common framework for integrating various devices and services, enabling smoother communication within heterogeneous environments.\n","\n","As edge computing applications continue to proliferate across industries—including healthcare, transportation, and smart cities—devising performance metrics to assess the efficiency of edge resources becomes increasingly critical. Performance indicators such as latency, data transfer rates, and resource utilization will help stakeholders measure the effectiveness of their edge implementations. New standards and benchmarks are being established to quantify these metrics, which will enable organizations to optimize their edge computing strategies for better service delivery.\n","\n","The advent of edge computing is ushering in a new era of technological standards and frameworks that facilitate the composition, communication, and management of edge resources. These developments are crucial for ensuring interoperability, security, and effective resource management in diverse environments. As organizations continue to adopt this paradigm, the emergence of standardized practices will be essential to address the complexities and challenges inherent in edge computing. Understanding these standards will not only aid in developing effective edge solutions but will also ensure that these solutions can collaborate seamlessly across a myriad of applications and contexts.\n","\n","    You are a computer science expert and a skilled writer.\n","\n","    Craft detailed content about the given computer science subtopic for university-level lecture notes, targeting a total of about 500 words distributed over a few paragraphs.\n","\n","    Begin with an introductory paragraph that lays the foundation of the subtopic. Follow this with detailed paragraphs focusing on the critical aspects of the subtopic. Include applications only if they are essential for understanding the concept; otherwise, concentrate on explaining the concept itself and its nuances.\n","\n","    You can selectively, if necessary, use examples, tables in Markdown format to illustrate key points, ensuring that any code provided is concise and directly demonstrates the concept, otherwise you don't need to include it.\n","\n","    Please also avoid overly detailed explanations of complex algorithms unless they are central to the subtopic. Do not go overboard with technical details that may overwhelm students.\n","\n","    Let's try to avoid generating code unless its short and obvious, otherwise, focus on detailed explanations and if you use equations, please use inline HTML. Quick and simple inline equations can utilize HTML ampersand entity codes, such as:\n","\n","        h<sub>&theta;</sub>(x) = &theta;<sub>o</sub> x + &theta;<sub>1</sub>x\n","\n","    This method works in practically all Markdown and does not require any external libraries. Avoid using LaTeX. If you cannot express it in HTML, please avoid using equations. Unless the symbol is simple and can be represented in HTML and Markdown, avoid using those symbols.\n","\n","    Let's try to avoid generating code unless its short and obvious, otherwise, focus on detailed explanations and if you use equations, please use LaTeX format.\n","\n","    Maintain clear and concise language suitable for a 10th-grade reading level, using academic language where appropriate. Avoid overly technical jargon unless it is necessary for clarity.\n","\n","    Also avoid your conclusion paragraph in the end since the content should be detailed throughout.\n","\n","    The entire response must be in valid Markdown format and avoid the use of diagrams unless they can be effectively represented in Markdown. You must stay in our limit of 500 words.\n","\n","    LaTeX is impossible to use in Markdown, so please use HTML for equations. Do not use LaTeX.\n","\n","    Your input will always be a single computer science subtopic, and your output should not conclude with a summarizing paragraph but rather emphasize detailed explanation throughout.\n","\n","\n","    Now, please generate detailed content about the subtopic in Markdown:\n","    \n","EXAMPLE:\n","\n","###INPUT (Notes): \n"," Recursion is often favored over traditional looping constructs in functional programming, allowing functions to call themselves to solve problems through base and recursive cases.\n","\n","###OUTPUT (Expected Generations):\n"," # Recursion in Functional Programming\n","\n","Recursion is a fundamental concept in functional programming that involves functions calling themselves to solve problems. This technique is particularly favored over traditional looping constructs like `for` and `while`, especially in languages that emphasize immutability and first-class functions. The recursive approach allows developers to express complex problems in a more elegant and readable way. A proper understanding of recursion includes distinguishing between the base case, which defines when the recursion stops, and the recursive case, which drives the recursion forward.\n","\n","## The Mechanics of Recursion\n","\n","At the heart of recursion lies the principle of breaking down a problem into smaller instances of the same problem. This is done until reaching a base case, which does not require further recursion. \n","\n","For example, consider calculating the factorial of a number, which is defined as the product of all positive integers up to that number. The factorial can be defined recursively as:\n","\n","- **Base Case:** The factorial of 0 is 1 (0! = 1).\n","- **Recursive Case:** The factorial of n is n multiplied by the factorial of (n - 1), represented as n! = n × (n - 1)!.\n","\n","This leads to a simple recursive function that can be expressed conceptually as follows:\n","\n","```markdown\n","factorial(n) = \n","  if n == 0 then 1 \n","  else n * factorial(n - 1)\n","```\n","\n","In a functional programming context, this recursive function replaces iterative constructs. Recursive functions can maintain clarity and focus on the outcome rather than the process, aligning well with the declarative nature of functional programming.\n","\n","## Advantages of Recursion \n","\n","One significant advantage of recursion is the simplicity it offers in terms of code readability and reduction in the number of lines of code necessary to implement various algorithms. Recursive solutions often align closely with the mathematical definitions of problems, making them easier to reason about. For instance, problems like tree traversals or the evaluation of nested structures (such as lists of lists) naturally fit into a recursive paradigm, as they can be defined in terms of smaller subproblems. \n","\n","Moreover, recursion fits well with immutability, another key principle of functional programming. Since recursive functions often return new data instead of modifying existing structures, they promote safer code that avoids side effects commonly found in mutable state.\n","\n","## Performance Considerations\n","\n","Despite its strengths, recursion can create performance challenges. Each recursive function call adds a new layer to the call stack, consuming memory. A deep recursion can lead to stack overflow errors if base cases are not adequately defined. To mitigate these issues, many functional programming languages support tail recursion optimization, enabling the reuse of stack frames for certain types of recursive calls. In tail recursion, the recursive call is the last operation in the function. This allows the language's runtime to optimize the call, reducing memory overhead.\n","\n","A clear example of tail recursion is in calculating Fibonacci numbers. The naive recursive approach can be inefficient due to repetitive computation. However, a tail-recursive approach maintains an accumulator for the result, minimizing the depth of the recursion:\n","\n","```markdown\n","fib(n, a=0, b=1) = \n","  if n == 0 then a \n","  else fib(n - 1, b, a + b)\n","```\n","\n","## Conclusion on Recursion\n","\n","While recursion can sometimes be less efficient than iterative solutions due to overhead, its elegance and expressiveness make it a powerful tool in functional programming. The ability to articulate complex problems in a recursive fashion allows functional programmers to create clear and concise solutions that often mirror theoretical definitions used in mathematics and computer science. This capability is essential as it promotes declarative programming, where the focus is on what to solve rather than how to solve it, aligning with the broader goals of functional programming.\n"]}],"source":["# Split the training data:\n","from sklearn.model_selection import train_test_split\n","\n","# Split the combined prompts into training, validation, and test sets\n","train_prompts, temp_prompts = train_test_split(combined_prompts, test_size=0.2, random_state=42)\n","val_prompts, test_prompts = train_test_split(temp_prompts, test_size=0.5, random_state=42)\n","\n","# Create a dataset dictionary for training, validation, and testing\n","train_dataset_dict = {'text': train_prompts}\n","val_dataset_dict = {'text': val_prompts}\n","test_dataset_dict = {'text': test_prompts}\n","\n","# Convert the dictionary to Dataset objects\n","train_dataset = Dataset.from_dict(train_dataset_dict)\n","val_dataset = Dataset.from_dict(val_dataset_dict)\n","test_dataset = Dataset.from_dict(test_dataset_dict)\n","\n","# Print a sample combined prompt to verify\n","print(train_dataset['text'][0])\n","print(val_dataset['text'][0])\n","print(test_dataset['text'][0])"]},{"cell_type":"markdown","metadata":{"id":"bfoJyhy4BBnp"},"source":["# Model Training"]},{"cell_type":"markdown","metadata":{"id":"SXd9bTZd1aaL"},"source":["We now add LoRA adapters so we only need to update 1 to 10% of all parameters! (Adapted from the Unsloth notebook)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6041,"status":"ok","timestamp":1723317965117,"user":{"displayName":"Tarun Vallabhaneni","userId":"14041432992530701793"},"user_tz":300},"id":"6bZsfBuZDeCL","outputId":"70a1a5c0-0830-4c3a-9474-3d75c58e5c7f"},"outputs":[{"name":"stderr","output_type":"stream","text":["Unsloth 2024.8 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"]}],"source":["model = FastLanguageModel.get_peft_model(\n","    model,\n","    r = 64, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n","    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n","    lora_alpha = 16,\n","    lora_dropout = 0, # Supports any, but = 0 is optimized\n","    bias = \"none\",    # Supports any, but = \"none\" is optimized\n","    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n","    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n","    random_state = 3407,\n","    use_rslora = False,  # We support rank stabilized LoRA\n","    loftq_config = None, # And LoftQ\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4139,"status":"ok","timestamp":1723421897926,"user":{"displayName":"Tarun Vallabhaneni","userId":"14041432992530701793"},"user_tz":300},"id":"peJdokW_YONY","outputId":"ec70eb79-7da9-4515-b33f-2898cb69b52e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting rouge_score\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.26.4)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2024.5.15)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.5)\n","Building wheels for collected packages: rouge_score\n","  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=5e63fc55125cc606d953f661e0b38c40d7dfdb3c91c8e8822be59142049e4114\n","  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n","Successfully built rouge_score\n","Installing collected packages: rouge_score\n","Successfully installed rouge_score-0.1.2\n"]}],"source":["!pip install rouge_score"]},{"cell_type":"markdown","metadata":{"id":"idAEIeSQ3xdS"},"source":["<a name=\"Train\"></a>\n","### Train the model\n","Now let's use Huggingface TRL's `SFTTrainer`! More docs here: [TRL SFT docs](https://huggingface.co/docs/trl/sft_trainer). We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`. We also support TRL's `DPOTrainer`!\n","(Adapted from the Unsloth notebook)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":136,"referenced_widgets":["376df4ede90244318635d1fbaa75b451","55570c1071e64402bc30d1c8acbff852","edd3e961326a4582a829f0fe40082585","742d11147cef456fa7dd486f52f9e9a3","e336d7ec98f44381ba91f55a7e56ce59","1d75c9a63d3f4e00a6134f03637bbc1c","4a13a2a18fcc4d598cd3f1c155201a59","706a44d8fd37475388999dd939494127","786952aab77a4de0bd0f572f56403f58","a81b75be9e0143cca512fafe6986dd30","ea9c804bec4c491ab70c83c29617fefc","030b169edfb242aaa4cad12af5ace7ca","94a3fbd072174512aaba86796b0bd3bb","72f8f33ce5ca489fbb10da819ea025b2","54cbf228233744229da38e65214ca117","95feb12225fd4c0f92ee73b12a783595","8a8eed470dfc4b328677f3b147b94273","e5f1518b43d94929b81adc992b00dd40","f0ba73def273443d9adee2839f21e1a6","ac1e827b2bef4211b435a4e938ea6678","692cf34a1ac2483bb149f3389232f044","ee8b1fa83656435d84fc79da27757701"]},"executionInfo":{"elapsed":6261,"status":"ok","timestamp":1723318034018,"user":{"displayName":"Tarun Vallabhaneni","userId":"14041432992530701793"},"user_tz":300},"id":"95_Nn-89DhsL","outputId":"ba87d76d-4a69-411a-98cb-d5e976b0f725"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"376df4ede90244318635d1fbaa75b451","version_major":2,"version_minor":0},"text/plain":["Map (num_proc=2):   0%|          | 0/1199 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"030b169edfb242aaa4cad12af5ace7ca","version_major":2,"version_minor":0},"text/plain":["Map (num_proc=2):   0%|          | 0/150 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from trl import SFTTrainer\n","from transformers import TrainingArguments\n","from unsloth import is_bfloat16_supported\n","\n","trainer = SFTTrainer(\n","    model = model,\n","    tokenizer = tokenizer,\n","    train_dataset = train_dataset,\n","    eval_dataset = val_dataset,\n","    dataset_text_field = \"text\",\n","    max_seq_length = max_seq_length,\n","    dataset_num_proc = 2,\n","    packing = False, # Can make training 5x faster for short sequences.\n","    # compute_metrics=compute_metrics,\n","    args = TrainingArguments(\n","        per_device_train_batch_size = 2,\n","        gradient_accumulation_steps = 4,\n","        warmup_steps = 30,\n","        num_train_epochs = 5, # Set this for 1 full training run.\n","        # max_steps = 60,\n","        learning_rate = 2e-4,\n","        fp16 = not is_bfloat16_supported(),\n","        bf16 = is_bfloat16_supported(),\n","        # logging_steps = 0.1,\n","        logging_steps = 20,\n","        optim = \"adamw_8bit\",\n","        weight_decay = 0.01,\n","        lr_scheduler_type = \"cosine\",\n","        seed = 3407,\n","        output_dir = \"outputs\",\n","        evaluation_strategy = \"epoch\",\n","        save_strategy=\"epoch\",\n","        load_best_model_at_end=True,\n","        metric_for_best_model=\"eval_loss\",\n","        report_to=\"wandb\",\n","        run_name=\"LLAMA-8B_run_5\",\n","    ),\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1723318034018,"user":{"displayName":"Tarun Vallabhaneni","userId":"14041432992530701793"},"user_tz":300},"id":"2ejIt2xSNKKp","outputId":"db6a8d41-e5d2-4628-80f5-f85bd0977acf"},"outputs":[{"name":"stdout","output_type":"stream","text":["GPU = NVIDIA A100-SXM4-40GB. Max memory = 39.564 GB.\n","6.457 GB of memory reserved.\n"]}],"source":["#@title Show current memory stats\n","gpu_stats = torch.cuda.get_device_properties(0)\n","start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n","max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n","print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n","print(f\"{start_gpu_memory} GB of memory reserved.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":319},"executionInfo":{"elapsed":2957548,"status":"ok","timestamp":1723321000485,"user":{"displayName":"Tarun Vallabhaneni","userId":"14041432992530701793"},"user_tz":300},"id":"yqxqAZ7KJ4oL","outputId":"5779a5ab-1466-41ca-f74e-0baf694b7d43"},"outputs":[{"name":"stderr","output_type":"stream","text":["==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n","   \\\\   /|    Num examples = 1,199 | Num Epochs = 5\n","O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n","\\        /    Total batch size = 8 | Total steps = 750\n"," \"-____-\"     Number of trainable parameters = 167,772,160\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [750/750 49:04, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.694800</td>\n","      <td>0.715897</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.650900</td>\n","      <td>0.704014</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.584200</td>\n","      <td>0.718662</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.489300</td>\n","      <td>0.756261</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.439600</td>\n","      <td>0.792841</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["trainer_stats = trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":346,"status":"ok","timestamp":1723321009860,"user":{"displayName":"Tarun Vallabhaneni","userId":"14041432992530701793"},"user_tz":300},"id":"pCqnaKmlO1U9","outputId":"fc707949-87d0-45c3-9f74-18f047aed45d"},"outputs":[{"name":"stdout","output_type":"stream","text":["2954.8328 seconds used for training.\n","49.25 minutes used for training.\n","Peak reserved memory = 19.771 GB.\n","Peak reserved memory for training = 13.314 GB.\n","Peak reserved memory % of max memory = 49.972 %.\n","Peak reserved memory for training % of max memory = 33.652 %.\n"]}],"source":["#@title Show final memory and time stats\n","used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n","used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n","used_percentage = round(used_memory         /max_memory*100, 3)\n","lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n","print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n","print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n","print(f\"Peak reserved memory = {used_memory} GB.\")\n","print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n","print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n","print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y1n5wFJt8PD3"},"outputs":[],"source":["best_model = trainer.model"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2112,"status":"ok","timestamp":1723322408277,"user":{"displayName":"Tarun Vallabhaneni","userId":"14041432992530701793"},"user_tz":300},"id":"bEL9QU4sBLtI","outputId":"73494e08-47a8-4d5e-deed-bfdbd0c83491"},"outputs":[{"data":{"text/plain":["('lora_model/tokenizer_config.json',\n"," 'lora_model/special_tokens_map.json',\n"," 'lora_model/tokenizer.json')"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["model.save_pretrained(\"lora_model\") # Local saving\n","tokenizer.save_pretrained(\"lora_model\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ohy0OGCNCD4H"},"outputs":[],"source":["!cp -r /content/lora_model '/content/drive/My Drive/NLP Final Project Data'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["2d613e15f9a3419e95eb1113b1e29996","496e40c0b9604dd59a592150c5c7e0d0","e8322dae282c4e96bd4f041ce16afc8a","b82ec2a9646344f8bf3d7c357e30f2f4","6e20ad9618e74264a4d235592dfb4d90","8d1cc6eafd044ae393cc64fe1a1bbc8f","527a98953ae0449ca0615455b2cd64a0","6aa1c8b4b6504368883b4fca23a41eb3","a563a3b1f65c4a04ac9e0edcb97824ae","a4cd170267b745c2904bb15baf17fa58","a2705fd109684193bc5567c3b3066259"]},"executionInfo":{"elapsed":965,"status":"ok","timestamp":1723321248064,"user":{"displayName":"Tarun Vallabhaneni","userId":"14041432992530701793"},"user_tz":300},"id":"bga3T3Ni81Fj","outputId":"3c076d6f-c4ba-4c46-891e-0bdb574de057"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2d613e15f9a3419e95eb1113b1e29996","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/150 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["def preprocess_function(examples):\n","    \"\"\"\n","    Preprocess the examples by tokenizing them and truncating/padding them to the maximum sequence length.\n","    Parameters:\n","        examples (dict): A dictionary of input examples.\n","    \"\"\"\n","    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=max_seq_length)\n","\n","tokenized_test_dataset = test_dataset.map(preprocess_function, batched=True, remove_columns=test_dataset.column_names)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":847,"referenced_widgets":["12a4ff8f447f4fe89ae6b516ea11f2bc","2faa0182764a4175a5884e8c1b599795","e6877dff742740a8a969ea0d2499e5e5","94dc5168aef045bbbde6786a38bdcaec","f06a83e1c6ad436788c260ad6cb8a958","54d0438fb156495683d66b7446758c85","ff6bf54c095a41478babeef663a7783d","b98644c687db4aa49546d52da1ca2728"]},"executionInfo":{"elapsed":31752,"status":"ok","timestamp":1723321288653,"user":{"displayName":"Tarun Vallabhaneni","userId":"14041432992530701793"},"user_tz":300},"id":"9YOvYzDYWuTt","outputId":"fa4a8ce4-7919-4bd0-ded6-5d5e212b6525"},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [19/19 00:26]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'eval_loss': 0.6908238530158997, 'eval_runtime': 27.8086, 'eval_samples_per_second': 5.394, 'eval_steps_per_second': 0.683, 'epoch': 5.0}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"12a4ff8f447f4fe89ae6b516ea11f2bc","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.047 MB of 0.047 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>▃▂▃▅█▁</td></tr><tr><td>eval/runtime</td><td>▁▁▁▁▁█</td></tr><tr><td>eval/samples_per_second</td><td>█████▁</td></tr><tr><td>eval/steps_per_second</td><td>█████▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇█████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇██████</td></tr><tr><td>train/grad_norm</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>train/learning_rate</td><td>▆██████▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/loss</td><td>0.69082</td></tr><tr><td>eval/runtime</td><td>27.8086</td></tr><tr><td>eval/samples_per_second</td><td>5.394</td></tr><tr><td>eval/steps_per_second</td><td>0.683</td></tr><tr><td>total_flos</td><td>3.651520822013952e+17</td></tr><tr><td>train/epoch</td><td>5</td></tr><tr><td>train/global_step</td><td>750</td></tr><tr><td>train/grad_norm</td><td>0.22059</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.4396</td></tr><tr><td>train_loss</td><td>0.59966</td></tr><tr><td>train_runtime</td><td>2954.8328</td></tr><tr><td>train_samples_per_second</td><td>2.029</td></tr><tr><td>train_steps_per_second</td><td>0.254</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">LLAMA 8B run_5</strong> at: <a href='https://wandb.ai/tvallabh-university-of-chicago/TextExpansions_NLP/runs/2ufzn07m' target=\"_blank\">https://wandb.ai/tvallabh-university-of-chicago/TextExpansions_NLP/runs/2ufzn07m</a><br/> View project at: <a href='https://wandb.ai/tvallabh-university-of-chicago/TextExpansions_NLP' target=\"_blank\">https://wandb.ai/tvallabh-university-of-chicago/TextExpansions_NLP</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20240810_192506-2ufzn07m/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["# After training, evaluate on the test set\n","test_results = trainer.evaluate(tokenized_test_dataset)\n","print(test_results)\n","\n","# Log the test results to wandb\n","wandb.log({\"test_results\": test_results})\n","# Close wandb run\n","wandb.finish()"]},{"cell_type":"markdown","metadata":{"id":"W3W6SBjn-kHS"},"source":["# Generating Expansions"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11692,"status":"ok","timestamp":1723427631213,"user":{"displayName":"Tarun Vallabhaneni","userId":"14041432992530701793"},"user_tz":300},"id":"wC8X7WND7Hwj","outputId":"fb856966-8b12-4d68-cee8-92a15633887d"},"outputs":[{"name":"stdout","output_type":"stream","text":["==((====))==  Unsloth 2024.8: Fast Llama patching. Transformers = 4.44.0.\n","   \\\\   /|    GPU: NVIDIA A100-SXM4-40GB. Max memory: 39.564 GB. Platform = Linux.\n","O^O/ \\_/ \\    Pytorch: 2.3.1+cu121. CUDA = 8.0. CUDA Toolkit = 12.1.\n","\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = False]\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"]}],"source":["base_model, base_tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",\n","    max_seq_length = max_seq_length,\n","    dtype = dtype,\n","    load_in_4bit = load_in_4bit,\n","    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cSf0gfKK7lvk"},"outputs":[],"source":["# Reuse the same parameters from training\n","max_seq_length = 2048\n","dtype = None  # None for auto detection\n","load_in_4bit = True\n","\n","# model, tokenizer = FastLanguageModel.from_pretrained(\n","#     model_name = \"lora_model\",  # The directory where your model was saved\n","#     max_seq_length = max_seq_length,\n","#     dtype = dtype,\n","#     load_in_4bit = load_in_4bit,\n","# )\n","\n","FastLanguageModel.for_inference(base_model)  # Enable native 2x faster inference"]},{"cell_type":"markdown","metadata":{"id":"9gspoFreBVVA"},"source":["## Base Model Expansions"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45568,"status":"ok","timestamp":1723428544453,"user":{"displayName":"Tarun Vallabhaneni","userId":"14041432992530701793"},"user_tz":300},"id":"4F-48ukb7SOY","outputId":"cdadfe21-74bf-43d8-dfcd-e70759938e2a"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","    You are a computer science expert and a skilled writer.\n","\n","    Craft detailed content about the given computer science subtopic for university-level lecture notes, targeting a total of about 500 words distributed over a few paragraphs.\n","\n","    Begin with an introductory paragraph that lays the foundation of the subtopic. Follow this with detailed paragraphs focusing on the critical aspects of the subtopic. Include applications only if they are essential for understanding the concept; otherwise, concentrate on explaining the concept itself and its nuances.\n","\n","    You can selectively, if necessary, use examples, tables in Markdown format to illustrate key points, ensuring that any code provided is concise and directly demonstrates the concept, otherwise you don't need to include it.\n","\n","    Please also avoid overly detailed explanations of complex algorithms unless they are central to the subtopic. Do not go overboard with technical details that may overwhelm students.\n","\n","    Let's try to avoid generating code unless its short and obvious, otherwise, focus on detailed explanations and if you use equations, please use inline HTML. Quick and simple inline equations can utilize HTML ampersand entity codes, such as:\n","\n","        h<sub>&theta;</sub>(x) = &theta;<sub>o</sub> x + &theta;<sub>1</sub>x\n","\n","    This method works in practically all Markdown and does not require any external libraries. Avoid using LaTeX. If you cannot express it in HTML, please avoid using equations. Unless the symbol is simple and can be represented in HTML and Markdown, avoid using those symbols.\n","\n","    Let's try to avoid generating code unless its short and obvious, otherwise, focus on detailed explanations and if you use equations, please use LaTeX format.\n","\n","    Maintain clear and concise language suitable for a 10th-grade reading level, using academic language where appropriate. Avoid overly technical jargon unless it is necessary for clarity.\n","\n","    Also avoid your conclusion paragraph in the end since the content should be detailed throughout.\n","\n","    The entire response must be in valid Markdown format and avoid the use of diagrams unless they can be effectively represented in Markdown. You must stay in our limit of 500 words.\n","\n","    LaTeX is impossible to use in Markdown, so please use HTML for equations. Do not use LaTeX.\n","\n","    Your input will always be a single computer science subtopic, and your output should not conclude with a summarizing paragraph but rather emphasize detailed explanation throughout.\n","\n","\n","    Now, please generate detailed content about the subtopic in Markdown:\n","    \n","\n","###INPUT (Notes):\n","A B-Tree is a self-balancing tree data structure that maintains sorted data and allows for efficient insertion, deletion, and search operations, making it ideal for database indexing.\n","\n","###OUTPUT (Expected Generations):\n","A B-Tree is a self-balancing tree data structure that maintains sorted data and allows for efficient insertion, deletion, and search operations, making it ideal for database indexing.\n","\n","####Introduction\n","\n","A B-Tree is a self-balancing tree data structure that maintains sorted data and allows for efficient insertion, deletion, and search operations, making it ideal for database indexing. It is a type of balanced tree, like an AVL tree or red-black tree, but it has a more complex structure that allows for efficient insertion and deletion.\n","\n","The B-Tree is a popular data structure in databases because it allows for fast access to data. It is often used as an index structure for databases, allowing for fast retrieval of data. The B-Tree is also used in other applications, such as file systems and caches.\n","\n","####Structure\n","\n","The structure of a B-Tree is similar to that of a binary search tree, but it has a more complex structure that allows for efficient insertion and deletion. The B-Tree is made up of nodes, and each node has a fixed number of keys and pointers. The keys are sorted in ascending order, and the pointers point to other nodes in the tree.\n","\n","The number of keys and pointers in each node is determined by the order of the B-Tree. The order of the B-Tree is the maximum number of keys in a node, and it is typically between 3 and 100. The order of the B-Tree determines the number of keys and pointers in each node, and it also determines the height of the tree.\n","\n","The height of the B-Tree is the number of levels in the tree. The height of the B-Tree is determined by the order of the B-Tree and the number of keys in each node. The height of the B-Tree is typically between 2 and 100.\n","\n","The B-Tree has a unique property that allows for efficient insertion and deletion. This property is called the balance property. The balance property ensures that the tree is balanced, meaning that the height of the tree is approximately the same for all nodes.\n","\n","The balance property is achieved by having a fixed number of keys and pointers in each node. The number of keys and pointers in each node is determined by the order of the B-Tree. The order of the B-Tree is typically between 3 and 100, and it determines the number of keys and pointers in each node.\n","\n","The height of the B-Tree is the number of levels in the tree. The height of the B-Tree is determined by the order of the B-Tree and the number of keys in each node. The height of the B-Tree is typically between 2 and 100.\n","\n","The B-Tree has a unique property that allows for efficient insertion and deletion. This property is called the balance property. The balance property ensures that the tree is balanced, meaning that the height of the tree is approximately the same for all nodes.\n","\n","The balance property is achieved by having a fixed number of keys and pointers in each node. The number of keys and pointers in each node is determined by the order of the B-Tree. The order of the B-Tree is typically between 3 and 100, and it determines the number of keys and pointers in each node.\n","\n","The height of the B-Tree is the number of levels in the tree. The height of the B-Tree is determined by the order of the B-Tree and the number of keys in each node. The height of the B-Tree is typically between 2 and 100.\n","\n","The B-Tree has a unique property that allows for efficient insertion and deletion. This property is called the balance property. The balance property ensures that the tree is balanced, meaning that the height of the tree is approximately the same for all nodes.\n","\n","The balance property is achieved by having a fixed number of keys and pointers in each node. The number of keys and pointers in each node is determined by the order of the B-Tree. The order of the B-Tree is typically between 3 and 100, and it determines the number of keys and pointers in each node.\n","\n","The height of the B-Tree is the number of levels in the tree. The height of the B-Tree is determined by the order of the B-Tree and the number of keys in each node. The height of the B-Tree is typically between 2 and 100.\n","\n","The B-Tree has a unique property that allows for efficient insertion and deletion. This property is called the balance property. The balance property ensures that the tree is balanced, meaning that the height of the tree is approximately the same for all nodes.\n","\n","The balance property is achieved by having a fixed number of keys and pointers in each node. The number of keys and pointers in each node is determined by the order of the B-Tree. The order of the B-Tree is typically between 3 and 100, and it determines the\n"]}],"source":["\n","# Define the prompt template\n","prompt_template = \"\"\"{instructions}\n","\n","###INPUT (Notes):\n","{input}\n","\n","###OUTPUT (Expected Generations):\n","{output}\"\"\"\n","\n","# Function to generate text\n","def generate_text(input_text, max_new_tokens=1000):\n","    \"\"\" \n","    Generate text based on the input text using the base model.\n","    Parameters:\n","        input_text (str): The input text to generate from.\n","        max_new_tokens (int): The maximum number of tokens to generate.\n","    \"\"\"\n","    prompt = prompt_template.format(\n","        instructions=instructions,\n","        input=input_text,\n","        output=\"\"  # Leave this blank for generation\n","    )\n","\n","    inputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n","\n","    with torch.no_grad():\n","        outputs = base_model.generate(\n","            **inputs,\n","            max_new_tokens=1000,\n","            use_cache=True,\n","            temperature=0.7,  # Adjust as needed\n","            top_p=0.9,  # Adjust as needed\n","        )\n","\n","    return base_tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","# Example usage\n","input_text = \"A B-Tree is a self-balancing tree data structure that maintains sorted data and allows for efficient insertion, deletion, and search operations, making it ideal for database indexing.\"\n","generated_text = generate_text(input_text)\n","print(generated_text)"]},{"cell_type":"markdown","metadata":{"id":"fu1PLaWyBcGE"},"source":["## Fine-Tuned Model Expansions"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":57423,"status":"ok","timestamp":1723323083678,"user":{"displayName":"Tarun Vallabhaneni","userId":"14041432992530701793"},"user_tz":300},"id":"RDb1XXU5-z-A","outputId":"7470b583-7110-464f-bc38-d2e48e87bf1f"},"outputs":[{"name":"stdout","output_type":"stream","text":["==((====))==  Unsloth 2024.8: Fast Llama patching. Transformers = 4.44.0.\n","   \\\\   /|    GPU: NVIDIA A100-SXM4-40GB. Max memory: 39.564 GB. Platform = Linux.\n","O^O/ \\_/ \\    Pytorch: 2.3.1+cu121. CUDA = 8.0. CUDA Toolkit = 12.1.\n","\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.26.post1. FA2 = False]\n"," \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n","Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","\n","    You are a computer science expert and a skilled writer.\n","\n","    Craft detailed content about the given computer science subtopic for university-level lecture notes, targeting a total of about 500 words distributed over a few paragraphs.\n","\n","    Begin with an introductory paragraph that lays the foundation of the subtopic. Follow this with detailed paragraphs focusing on the critical aspects of the subtopic. Include applications only if they are essential for understanding the concept; otherwise, concentrate on explaining the concept itself and its nuances.\n","\n","    You can selectively, if necessary, use examples, tables in Markdown format to illustrate key points, ensuring that any code provided is concise and directly demonstrates the concept, otherwise you don't need to include it.\n","\n","    Please also avoid overly detailed explanations of complex algorithms unless they are central to the subtopic. Do not go overboard with technical details that may overwhelm students.\n","\n","    Let's try to avoid generating code unless its short and obvious, otherwise, focus on detailed explanations and if you use equations, please use inline HTML. Quick and simple inline equations can utilize HTML ampersand entity codes, such as:\n","\n","        h<sub>&theta;</sub>(x) = &theta;<sub>o</sub> x + &theta;<sub>1</sub>x\n","\n","    This method works in practically all Markdown and does not require any external libraries. Avoid using LaTeX. If you cannot express it in HTML, please avoid using equations. Unless the symbol is simple and can be represented in HTML and Markdown, avoid using those symbols.\n","\n","    Let's try to avoid generating code unless its short and obvious, otherwise, focus on detailed explanations and if you use equations, please use LaTeX format.\n","\n","    Maintain clear and concise language suitable for a 10th-grade reading level, using academic language where appropriate. Avoid overly technical jargon unless it is necessary for clarity.\n","\n","    Also avoid your conclusion paragraph in the end since the content should be detailed throughout.\n","\n","    The entire response must be in valid Markdown format and avoid the use of diagrams unless they can be effectively represented in Markdown. You must stay in our limit of 500 words.\n","\n","    LaTeX is impossible to use in Markdown, so please use HTML for equations. Do not use LaTeX.\n","\n","    Your input will always be a single computer science subtopic, and your output should not conclude with a summarizing paragraph but rather emphasize detailed explanation throughout.\n","\n","\n","    Now, please generate detailed content about the subtopic in Markdown:\n","    \n","\n","###INPUT (Notes): \n","Explain the concept of recursion in programming.\n","\n","###OUTPUT (Expected Generations):\n","# Recursion in Programming\n","\n","Recursion is a powerful programming paradigm that allows a function to call itself. It is a method of implementing algorithms that can be expressed in a way that a function solves smaller instances of the same problem. This approach can lead to elegant and concise solutions for various computational problems. Understanding recursion is crucial for programming, as it not only simplifies the implementation of algorithms but also enhances problem-solving skills.\n","\n","At its core, recursion relies on the concept of base cases and recursive cases. A base case is a condition where the recursion stops, and a solution is returned. In contrast, the recursive case is where the function calls itself to solve smaller instances of the same problem. This process continues until the base case is reached, allowing the function to build up a solution from smaller pieces. The recursive call can be seen as a contract between the function and the caller, where the function promises to return a result based on smaller instances of the problem.\n","\n","A classic example of recursion is the factorial function. The factorial of a non-negative integer n is defined as:\n","\n","&n factorial; = n × (n - 1) × (n - 2) ×... × 1\n","\n","The recursive definition of factorial can be expressed as follows:\n","\n","```plaintext\n","factorial(n) = \n","    if n == 0: \n","        return 1 \n","    else:\n","        return n * factorial(n-1)\n","```\n","\n","In this example, the function checks if the input `n` is zero. If it is, it returns 1 (the base case). If `n` is not zero, it calls itself with `n-1`. This recursive approach allows the function to compute the factorial of larger numbers by breaking them down into smaller, manageable pieces.\n","\n","Another key aspect of recursion is its use of the call stack. Each recursive call creates a new frame on the call stack, which stores the function's arguments and local variables. This stack can grow quite large, especially for deeply recursive functions, leading to stack overflow errors if the depth exceeds the stack size. Therefore, it is important to manage recursion carefully, ensuring that base cases are defined to prevent infinite loops.\n","\n","The performance of recursive algorithms can vary widely. While they can be elegant and intuitive, they may not always be the most efficient. Recursive algorithms often require additional memory to store the function calls on the call stack. In contrast, iterative algorithms, which use loops, may consume less memory but can be less readable and maintainable. For complex problems, a hybrid approach, combining recursion and iteration, can be advantageous, leveraging the strengths of both methods.\n","\n","Here’s a simple comparison of recursion and iteration:\n","\n","| Aspect               | Recursion         | Iteration        |\n","|---------------------|-------------------|------------------|\n","| Structure           | Hierarchical      | Linear           |\n","| Memory Usage        | Higher            | Lower            |\n","| Readability         | Often more clear  | May be more clear|\n","| Performance         | Varies            | More predictable  |\n","\n","In conclusion, recursion is a fundamental concept in programming that enables the implementation of algorithms through self-calling functions. It allows for elegant solutions to complex problems, but careful management of stack usage and base cases is essential for efficient and effective programming. Understanding recursion not only enhances problem-solving skills but also prepares programmers for the challenges of advanced algorithm design and analysis.\n"]}],"source":["from unsloth import FastLanguageModel\n","import torch\n","\n","# Reuse the same parameters from training\n","max_seq_length = 2048\n","dtype = None  # None for auto detection\n","load_in_4bit = True\n","\n","# model, tokenizer = FastLanguageModel.from_pretrained(\n","#     model_name = \"lora_model\",  # The directory where your model was saved\n","#     max_seq_length = max_seq_length,\n","#     dtype = dtype,\n","#     load_in_4bit = load_in_4bit,\n","# )\n","\n","FastLanguageModel.for_inference(model)  # Enable native 2x faster inference\n","\n","# Define the prompt template\n","prompt_template = \"\"\"{instructions}\n","\n","###INPUT (Notes):\n","{input}\n","\n","###OUTPUT (Expected Generations):\n","{output}\"\"\"\n","\n","# Function to generate text\n","def generate_text(input_text, max_new_tokens=1000):\n","    \"\"\" \n","    Generate text based on the input text using the fine-tuned model.\n","    Parameters:\n","        input_text (str): The input text to generate from.\n","        max_new_tokens (int): The maximum number of tokens to generate.\n","    \"\"\"\n","    prompt = prompt_template.format(\n","        instructions=instructions,\n","        input=input_text,\n","        output=\"\"  # Leave this blank for generation\n","    )\n","\n","    inputs = tokenizer([prompt], return_tensors=\"pt\").to(\"cuda\")\n","\n","    with torch.no_grad():\n","        outputs = model.generate(\n","            **inputs,\n","            max_new_tokens=1000,\n","            use_cache=True,\n","            temperature=0.7,  # Adjust as needed\n","            top_p=0.9,  # Adjust as needed\n","        )\n","\n","    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n","\n","# Example usage\n","input_text = \"Explain the concept of recursion in programming.\"\n","generated_text = generate_text(input_text)\n","print(generated_text)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3399,"status":"ok","timestamp":1723323633964,"user":{"displayName":"Tarun Vallabhaneni","userId":"14041432992530701793"},"user_tz":300},"id":"QaXzRZeSF7vh","outputId":"89a9e55a-97f5-46ab-bab7-39ef26636047"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install -q datasets sacrebleu nltk"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":756,"status":"ok","timestamp":1723323641188,"user":{"displayName":"Tarun Vallabhaneni","userId":"14041432992530701793"},"user_tz":300},"id":"tqoGhhQpF-SL","outputId":"dec430d9-ed8b-450a-eab0-37d77d6d99ce"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"data":{"text/plain":["True"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["import nltk\n","nltk.download('punkt')"]},{"cell_type":"markdown","metadata":{"id":"7QK9R8mHBgHr"},"source":["# Quantitative Analysis"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2586,"status":"ok","timestamp":1723422256345,"user":{"displayName":"Tarun Vallabhaneni","userId":"14041432992530701793"},"user_tz":300},"id":"S_McoUZvFNhF","outputId":"eacd5eef-f680-4987-f748-25f2d79c0494"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]}],"source":["from datasets import load_metric\n","from tqdm import tqdm\n","import torch\n","# from sacrebleu.metrics import BLEU\n","\n","# Load metrics\n","rouge = load_metric(\"rouge\")\n","meteor = load_metric(\"meteor\")\n","# bleu = BLEU()\n","\n","def evaluate_model(model, tokenizer, test_dataset, batch_size=4):\n","    \"\"\" \n","    Evaluate the model on the test dataset using ROUGE and METEOR metrics.\n","    Parameters:\n","        model (transformers.PreTrainedModel): The model to evaluate.\n","        tokenizer (transformers.PreTrainedTokenizerFast): The tokenizer to use.\n","        test_dataset (datasets.Dataset): The test dataset to evaluate on.\n","        batch_size (int): The batch size for evaluation.\n","    \"\"\"\n","    model.eval()\n","    predictions = []\n","    references = []\n","\n","    for i in tqdm(range(0, len(test_dataset), batch_size)):\n","        batch = test_dataset[i:i+batch_size]\n","\n","        # Extract inputs and references from the batch\n","        inputs = batch['text']\n","        batch_references = batch['text']  # Assuming references are in the same 'text' field\n","\n","        # Generate predictions\n","        encoded_inputs = tokenizer(inputs, return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n","        with torch.no_grad():\n","            outputs = model.generate(**encoded_inputs, max_new_tokens=1000)\n","\n","        batch_predictions = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n","\n","        # Process predictions and references\n","        for pred, ref in zip(batch_predictions, batch_references):\n","            # Extract generated content (after \"###OUTPUT (Expected Generations):\")\n","            pred_content = pred.split(\"###OUTPUT (Expected Generations):\")[-1].strip()\n","            predictions.append(pred_content)\n","\n","            # Extract reference content (after \"###OUTPUT (Expected Generations):\")\n","            ref_content = ref.split(\"###OUTPUT (Expected Generations):\")[-1].strip()\n","            references.append(ref_content)\n","\n","    # Calculate ROUGE scores\n","    rouge_scores = rouge.compute(predictions=predictions, references=references, use_stemmer=True)\n","\n","    # Calculate METEOR score\n","    meteor_score = meteor.compute(predictions=predictions, references=references)\n","\n","    # Calculate BLEU score\n","    # bleu_score = bleu.corpus_score(predictions, [references])\n","\n","    # Print results\n","    print(f\"ROUGE-1: {rouge_scores['rouge1'].mid.fmeasure:.4f}\")\n","    print(f\"ROUGE-2: {rouge_scores['rouge2'].mid.fmeasure:.4f}\")\n","    print(f\"ROUGE-L: {rouge_scores['rougeL'].mid.fmeasure:.4f}\")\n","    print(f\"METEOR: {meteor_score['meteor']:.4f}\")\n","    # print(f\"BLEU: {bleu_score.score:.4f}\")\n","\n","    return predictions, references\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":355156,"status":"ok","timestamp":1723324090364,"user":{"displayName":"Tarun Vallabhaneni","userId":"14041432992530701793"},"user_tz":300},"id":"PAAVcSY4FQJr","outputId":"28a6ac9e-b128-40e7-9d3b-1418c30da25c"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 38/38 [04:58<00:00,  7.86s/it]\n"]},{"name":"stdout","output_type":"stream","text":["ROUGE-1: 0.9750\n","ROUGE-2: 0.9752\n","ROUGE-L: 0.9753\n","METEOR: 0.9481\n","BLEU: 95.0070\n"]}],"source":["predictions, references = evaluate_model(model, tokenizer, test_dataset)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":850055,"status":"ok","timestamp":1723423137578,"user":{"displayName":"Tarun Vallabhaneni","userId":"14041432992530701793"},"user_tz":300},"id":"73TEhj_K8obF","outputId":"c2d6a612-ef72-4ed9-f311-26b788ca2280"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 38/38 [13:12<00:00, 20.86s/it]\n"]},{"name":"stdout","output_type":"stream","text":["ROUGE-1: 0.9636\n","ROUGE-2: 0.9638\n","ROUGE-L: 0.9635\n","METEOR: 0.9617\n"]}],"source":["predictions, references = evaluate_model(base_model, base_tokenizer, test_dataset)\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"030b169edfb242aaa4cad12af5ace7ca":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_94a3fbd072174512aaba86796b0bd3bb","IPY_MODEL_72f8f33ce5ca489fbb10da819ea025b2","IPY_MODEL_54cbf228233744229da38e65214ca117"],"layout":"IPY_MODEL_95feb12225fd4c0f92ee73b12a783595"}},"068b2dd671314903ae5f3b7ada76f4f7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f97762caade48e7ac47455ac4dee749","placeholder":"​","style":"IPY_MODEL_ad19a1332abd4a6c8b09d85b2cd89540","value":"special_tokens_map.json: 100%"}},"0ce50666c0074d43854298c0eb4aad34":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"12a4ff8f447f4fe89ae6b516ea11f2bc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_2faa0182764a4175a5884e8c1b599795","IPY_MODEL_e6877dff742740a8a969ea0d2499e5e5"],"layout":"IPY_MODEL_94dc5168aef045bbbde6786a38bdcaec"}},"1326089ddb8f4be4954a11c772f3a68a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_068b2dd671314903ae5f3b7ada76f4f7","IPY_MODEL_b408f64cbabc4173ba59517f61016386","IPY_MODEL_f238fbb4b5294fedbb70492bd96fa2ac"],"layout":"IPY_MODEL_e4d03ae801744b10b1d51a0d51ff6295"}},"1882a35635fc40a09cc64dd8980c52ef":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bfd11c7cdfb14e08a8eaf14df7d0c2e1","IPY_MODEL_71071d14ea894a23bfdc91cfe9cb82fd","IPY_MODEL_5a4e62ee241a4dd4b2b3fabb13542caa"],"layout":"IPY_MODEL_ee8f1835a95043989f77adc8d876063f"}},"1d75c9a63d3f4e00a6134f03637bbc1c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f0cff853cfa4337aa78fbaeaac3b781":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25755d03fbdc42c1b91af5861b5e8ff2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27553a8863834b0197be5db14092fc77":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2b173a01f971458782f913b0fc518203":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2d613e15f9a3419e95eb1113b1e29996":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_496e40c0b9604dd59a592150c5c7e0d0","IPY_MODEL_e8322dae282c4e96bd4f041ce16afc8a","IPY_MODEL_b82ec2a9646344f8bf3d7c357e30f2f4"],"layout":"IPY_MODEL_6e20ad9618e74264a4d235592dfb4d90"}},"2d9b683a514f44b8aeeeb91bf09335b8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_936b5e41270a411fbad754297ea85480","max":5702746390,"min":0,"orientation":"horizontal","style":"IPY_MODEL_807353ff8c0c40c09b552c65b1a014d0","value":5702745847}},"2faa0182764a4175a5884e8c1b599795":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f06a83e1c6ad436788c260ad6cb8a958","placeholder":"​","style":"IPY_MODEL_54d0438fb156495683d66b7446758c85","value":"0.047 MB of 0.047 MB uploaded\r"}},"376df4ede90244318635d1fbaa75b451":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_55570c1071e64402bc30d1c8acbff852","IPY_MODEL_edd3e961326a4582a829f0fe40082585","IPY_MODEL_742d11147cef456fa7dd486f52f9e9a3"],"layout":"IPY_MODEL_e336d7ec98f44381ba91f55a7e56ce59"}},"3b42b0dbd3854c4baa57394475beee45":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4283c8e6204246f1bdd2479fa14858b8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"43199e19ac254902aa09ee42b0622cec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"449b8e23151c4a228f27b5eb6531e295":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"45932f6a791f4d00806844d9f1ab7d78":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"496e40c0b9604dd59a592150c5c7e0d0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d1cc6eafd044ae393cc64fe1a1bbc8f","placeholder":"​","style":"IPY_MODEL_527a98953ae0449ca0615455b2cd64a0","value":"Map: 100%"}},"4a13a2a18fcc4d598cd3f1c155201a59":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a82a1f7f0c74b209fff515103254e92":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9be948479d4b4984a66d799fc38ef931","max":50570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6c3bc83eedc3426eab31cc4eff3acb2d","value":50570}},"4f709ea116504c06b935164f17033a2a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f0884ec8d6ea494eaaf3b1fdb10c1a58","placeholder":"​","style":"IPY_MODEL_2b173a01f971458782f913b0fc518203","value":" 5.70G/5.70G [00:15&lt;00:00, 397MB/s]"}},"52533fc9671c4ea5996dbaeb94bae905":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"527a98953ae0449ca0615455b2cd64a0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"54cbf228233744229da38e65214ca117":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_692cf34a1ac2483bb149f3389232f044","placeholder":"​","style":"IPY_MODEL_ee8b1fa83656435d84fc79da27757701","value":" 150/150 [00:01&lt;00:00, 124.75 examples/s]"}},"54d0438fb156495683d66b7446758c85":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"55570c1071e64402bc30d1c8acbff852":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d75c9a63d3f4e00a6134f03637bbc1c","placeholder":"​","style":"IPY_MODEL_4a13a2a18fcc4d598cd3f1c155201a59","value":"Map (num_proc=2): 100%"}},"5a4e62ee241a4dd4b2b3fabb13542caa":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_25755d03fbdc42c1b91af5861b5e8ff2","placeholder":"​","style":"IPY_MODEL_27553a8863834b0197be5db14092fc77","value":" 9.09M/9.09M [00:01&lt;00:00, 8.29MB/s]"}},"5d542214fa5b4e57b4a173e6821635d0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5f74db3a779548a59abae59cfa5e414f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f867cb94def411381615d2448facbbe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6116a8d8133d43f691f13babafaf21b1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff23c97dd8c04cfe872e8e8d8fe3d378","max":230,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4283c8e6204246f1bdd2479fa14858b8","value":230}},"66aeebe7538e4034bc79b4919d9d2dcd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8ded83de37740e5b01ac578ec0caf89","placeholder":"​","style":"IPY_MODEL_1f0cff853cfa4337aa78fbaeaac3b781","value":"model.safetensors: 100%"}},"692cf34a1ac2483bb149f3389232f044":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6aa1c8b4b6504368883b4fca23a41eb3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c3bc83eedc3426eab31cc4eff3acb2d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6e20ad9618e74264a4d235592dfb4d90":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"706a44d8fd37475388999dd939494127":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71071d14ea894a23bfdc91cfe9cb82fd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b42b0dbd3854c4baa57394475beee45","max":9085657,"min":0,"orientation":"horizontal","style":"IPY_MODEL_45932f6a791f4d00806844d9f1ab7d78","value":9085657}},"726c371a807341bba4c166bb3d7e4cf2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_73950018b9874d17bf94bc31ffa3c6e8","placeholder":"​","style":"IPY_MODEL_0ce50666c0074d43854298c0eb4aad34","value":"generation_config.json: 100%"}},"72f8f33ce5ca489fbb10da819ea025b2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f0ba73def273443d9adee2839f21e1a6","max":150,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ac1e827b2bef4211b435a4e938ea6678","value":150}},"73950018b9874d17bf94bc31ffa3c6e8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"742d11147cef456fa7dd486f52f9e9a3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a81b75be9e0143cca512fafe6986dd30","placeholder":"​","style":"IPY_MODEL_ea9c804bec4c491ab70c83c29617fefc","value":" 1199/1199 [00:03&lt;00:00, 370.70 examples/s]"}},"786952aab77a4de0bd0f572f56403f58":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7f97762caade48e7ac47455ac4dee749":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"807353ff8c0c40c09b552c65b1a014d0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8774933244864d98a94c67d54040f7d4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d0cdad457a024eb3bdc50823bc99ad3c","placeholder":"​","style":"IPY_MODEL_5f867cb94def411381615d2448facbbe","value":"tokenizer_config.json: 100%"}},"8a8eed470dfc4b328677f3b147b94273":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d1cc6eafd044ae393cc64fe1a1bbc8f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e416d25d24a43fda6e32772c8f1254b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_726c371a807341bba4c166bb3d7e4cf2","IPY_MODEL_6116a8d8133d43f691f13babafaf21b1","IPY_MODEL_a0139421746a47fe9100dd2d51f008e8"],"layout":"IPY_MODEL_9d87b6dbd5e040da9fee8938800c8564"}},"936b5e41270a411fbad754297ea85480":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"94a3fbd072174512aaba86796b0bd3bb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a8eed470dfc4b328677f3b147b94273","placeholder":"​","style":"IPY_MODEL_e5f1518b43d94929b81adc992b00dd40","value":"Map (num_proc=2): 100%"}},"94dc5168aef045bbbde6786a38bdcaec":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95feb12225fd4c0f92ee73b12a783595":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ace2359a8824913877180b4743ad104":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9be948479d4b4984a66d799fc38ef931":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d87b6dbd5e040da9fee8938800c8564":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0139421746a47fe9100dd2d51f008e8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9ace2359a8824913877180b4743ad104","placeholder":"​","style":"IPY_MODEL_c41949581145451d89d178ba853a3d7c","value":" 230/230 [00:00&lt;00:00, 20.2kB/s]"}},"a2705fd109684193bc5567c3b3066259":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a4ab84665b2e400c9b8ea400d3fd3517":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4cd170267b745c2904bb15baf17fa58":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a563a3b1f65c4a04ac9e0edcb97824ae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a6ae176d88d54fc5b06382b93f953340":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_66aeebe7538e4034bc79b4919d9d2dcd","IPY_MODEL_2d9b683a514f44b8aeeeb91bf09335b8","IPY_MODEL_4f709ea116504c06b935164f17033a2a"],"layout":"IPY_MODEL_d2cfa05227274df5bbaa1906011482c5"}},"a81b75be9e0143cca512fafe6986dd30":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac1e827b2bef4211b435a4e938ea6678":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ad19a1332abd4a6c8b09d85b2cd89540":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b0fa405d4e5740b0b76da36e6d09fbb1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8774933244864d98a94c67d54040f7d4","IPY_MODEL_4a82a1f7f0c74b209fff515103254e92","IPY_MODEL_b1f30e1bf9984b3eaaf4b55e97e32355"],"layout":"IPY_MODEL_c1d20772376b454482994e36e14193c3"}},"b1f30e1bf9984b3eaaf4b55e97e32355":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ddca7425fe2548aa8b69991123932c90","placeholder":"​","style":"IPY_MODEL_5d542214fa5b4e57b4a173e6821635d0","value":" 50.6k/50.6k [00:00&lt;00:00, 3.58MB/s]"}},"b408f64cbabc4173ba59517f61016386":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_52533fc9671c4ea5996dbaeb94bae905","max":345,"min":0,"orientation":"horizontal","style":"IPY_MODEL_43199e19ac254902aa09ee42b0622cec","value":345}},"b82ec2a9646344f8bf3d7c357e30f2f4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4cd170267b745c2904bb15baf17fa58","placeholder":"​","style":"IPY_MODEL_a2705fd109684193bc5567c3b3066259","value":" 150/150 [00:00&lt;00:00, 252.12 examples/s]"}},"b98644c687db4aa49546d52da1ca2728":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bfd11c7cdfb14e08a8eaf14df7d0c2e1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f74db3a779548a59abae59cfa5e414f","placeholder":"​","style":"IPY_MODEL_449b8e23151c4a228f27b5eb6531e295","value":"tokenizer.json: 100%"}},"c1d20772376b454482994e36e14193c3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c41949581145451d89d178ba853a3d7c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d0cdad457a024eb3bdc50823bc99ad3c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2cfa05227274df5bbaa1906011482c5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ddca7425fe2548aa8b69991123932c90":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e336d7ec98f44381ba91f55a7e56ce59":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4d03ae801744b10b1d51a0d51ff6295":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5f1518b43d94929b81adc992b00dd40":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e6877dff742740a8a969ea0d2499e5e5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff6bf54c095a41478babeef663a7783d","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b98644c687db4aa49546d52da1ca2728","value":1}},"e8322dae282c4e96bd4f041ce16afc8a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6aa1c8b4b6504368883b4fca23a41eb3","max":150,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a563a3b1f65c4a04ac9e0edcb97824ae","value":150}},"e8ded83de37740e5b01ac578ec0caf89":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ea9c804bec4c491ab70c83c29617fefc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eb4db9b805594e11829474747dea80ed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"edd3e961326a4582a829f0fe40082585":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_706a44d8fd37475388999dd939494127","max":1199,"min":0,"orientation":"horizontal","style":"IPY_MODEL_786952aab77a4de0bd0f572f56403f58","value":1199}},"ee8b1fa83656435d84fc79da27757701":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ee8f1835a95043989f77adc8d876063f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f06a83e1c6ad436788c260ad6cb8a958":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0884ec8d6ea494eaaf3b1fdb10c1a58":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f0ba73def273443d9adee2839f21e1a6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f238fbb4b5294fedbb70492bd96fa2ac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4ab84665b2e400c9b8ea400d3fd3517","placeholder":"​","style":"IPY_MODEL_eb4db9b805594e11829474747dea80ed","value":" 345/345 [00:00&lt;00:00, 27.6kB/s]"}},"ff23c97dd8c04cfe872e8e8d8fe3d378":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff6bf54c095a41478babeef663a7783d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
